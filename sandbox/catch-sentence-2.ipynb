{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowboy.snowboydetect import SnowboyDetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import audioop\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = audio.get_device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use device at position zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_info = audio.get_device_info_by_index(device_index)\n",
    "sample_rate = int(device_info[\"defaultSampleRate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = pyaudio.paInt16\n",
    "SAMPLE_WIDTH = pyaudio.get_sample_size(form)\n",
    "SAMPLE_RATE = sample_rate\n",
    "CHUNK = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microphone stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneStream(object):\n",
    "    def __init__(self, pyaudio_stream):\n",
    "        self.pyaudio_stream = pyaudio_stream\n",
    "\n",
    "    def read(self, size):\n",
    "        return self.pyaudio_stream.read(size, exception_on_overflow=False)\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            # sometimes, if the stream isn't stopped, closing the stream throws an exception\n",
    "            if not self.pyaudio_stream.is_stopped():\n",
    "                self.pyaudio_stream.stop_stream()\n",
    "        finally:\n",
    "            self.pyaudio_stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = MicrophoneStream(\n",
    "    audio.open(\n",
    "        input_device_index=device_index, channels=1, format=form,\n",
    "        rate=SAMPLE_RATE, frames_per_buffer=CHUNK, input=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioData(object):\n",
    "    \"\"\"\n",
    "    Creates a new ``AudioData`` instance, which represents mono audio data.\n",
    "    The raw audio data is specified by ``frame_data``, which is a sequence of bytes representing audio samples. This is the frame data structure used by the PCM WAV format.\n",
    "    The width of each sample, in bytes, is specified by ``sample_width``. Each group of ``sample_width`` bytes represents a single audio sample.\n",
    "    The audio data is assumed to have a sample rate of ``sample_rate`` samples per second (Hertz).\n",
    "    Usually, instances of this class are obtained from ``recognizer_instance.record`` or ``recognizer_instance.listen``, or in the callback for ``recognizer_instance.listen_in_background``, rather than instantiating them directly.\n",
    "    \"\"\"\n",
    "    def __init__(self, frame_data, sample_rate, sample_width):\n",
    "        assert sample_rate > 0, \"Sample rate must be a positive integer\"\n",
    "        assert sample_width % 1 == 0 and 1 <= sample_width <= 4, \"Sample width must be between 1 and 4 inclusive\"\n",
    "        self.frame_data = frame_data\n",
    "        self.sample_rate = sample_rate\n",
    "        self.sample_width = int(sample_width)\n",
    "\n",
    "    def get_segment(self, start_ms=None, end_ms=None):\n",
    "        \"\"\"\n",
    "        Returns a new ``AudioData`` instance, trimmed to a given time interval. In other words, an ``AudioData`` instance with the same audio data except starting at ``start_ms`` milliseconds in and ending ``end_ms`` milliseconds in.\n",
    "        If not specified, ``start_ms`` defaults to the beginning of the audio, and ``end_ms`` defaults to the end.\n",
    "        \"\"\"\n",
    "        assert start_ms is None or start_ms >= 0, \"``start_ms`` must be a non-negative number\"\n",
    "        assert end_ms is None or end_ms >= (0 if start_ms is None else start_ms), \"``end_ms`` must be a non-negative number greater or equal to ``start_ms``\"\n",
    "        if start_ms is None:\n",
    "            start_byte = 0\n",
    "        else:\n",
    "            start_byte = int((start_ms * self.sample_rate * self.sample_width) // 1000)\n",
    "        if end_ms is None:\n",
    "            end_byte = len(self.frame_data)\n",
    "        else:\n",
    "            end_byte = int((end_ms * self.sample_rate * self.sample_width) // 1000)\n",
    "        return AudioData(self.frame_data[start_byte:end_byte], self.sample_rate, self.sample_width)\n",
    "\n",
    "    def get_raw_data(self, convert_rate=None, convert_width=None):\n",
    "        \"\"\"\n",
    "        Returns a byte string representing the raw frame data for the audio represented by the ``AudioData`` instance.\n",
    "        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n",
    "        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n",
    "        Writing these bytes directly to a file results in a valid `RAW/PCM audio file <https://en.wikipedia.org/wiki/Raw_audio_format>`__.\n",
    "        \"\"\"\n",
    "        assert convert_rate is None or convert_rate > 0, \"Sample rate to convert to must be a positive integer\"\n",
    "        assert convert_width is None or (convert_width % 1 == 0 and 1 <= convert_width <= 4), \"Sample width to convert to must be between 1 and 4 inclusive\"\n",
    "\n",
    "        raw_data = self.frame_data\n",
    "\n",
    "        # make sure unsigned 8-bit audio (which uses unsigned samples) is handled like higher sample width audio (which uses signed samples)\n",
    "        if self.sample_width == 1:\n",
    "            raw_data = audioop.bias(raw_data, 1, -128)  # subtract 128 from every sample to make them act like signed samples\n",
    "\n",
    "        # resample audio at the desired rate if specified\n",
    "        if convert_rate is not None and self.sample_rate != convert_rate:\n",
    "            raw_data, _ = audioop.ratecv(raw_data, self.sample_width, 1, self.sample_rate, convert_rate, None)\n",
    "\n",
    "        # convert samples to desired sample width if specified\n",
    "        if convert_width is not None and self.sample_width != convert_width:\n",
    "            if convert_width == 3:  # we're converting the audio into 24-bit (workaround for https://bugs.python.org/issue12866)\n",
    "                raw_data = audioop.lin2lin(raw_data, self.sample_width, 4)  # convert audio into 32-bit first, which is always supported\n",
    "                try: audioop.bias(b\"\", 3, 0)  # test whether 24-bit audio is supported (for example, ``audioop`` in Python 3.3 and below don't support sample width 3, while Python 3.4+ do)\n",
    "                except audioop.error:  # this version of audioop doesn't support 24-bit audio (probably Python 3.3 or less)\n",
    "                    raw_data = b\"\".join(raw_data[i + 1:i + 4] for i in range(0, len(raw_data), 4))  # since we're in little endian, we discard the first byte from each 32-bit sample to get a 24-bit sample\n",
    "                else:  # 24-bit audio fully supported, we don't need to shim anything\n",
    "                    raw_data = audioop.lin2lin(raw_data, self.sample_width, convert_width)\n",
    "            else:\n",
    "                raw_data = audioop.lin2lin(raw_data, self.sample_width, convert_width)\n",
    "\n",
    "        # if the output is 8-bit audio with unsigned samples, convert the samples we've been treating as signed to unsigned again\n",
    "        if convert_width == 1:\n",
    "            raw_data = audioop.bias(raw_data, 1, 128)  # add 128 to every sample to make them act like unsigned samples again\n",
    "\n",
    "        return raw_data\n",
    "\n",
    "    def get_wav_data(self, convert_rate=None, convert_width=None):\n",
    "        \"\"\"\n",
    "        Returns a byte string representing the contents of a WAV file containing the audio represented by the ``AudioData`` instance.\n",
    "        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n",
    "        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n",
    "        Writing these bytes directly to a file results in a valid `WAV file <https://en.wikipedia.org/wiki/WAV>`__.\n",
    "        \"\"\"\n",
    "        raw_data = self.get_raw_data(convert_rate, convert_width)\n",
    "        sample_rate = self.sample_rate if convert_rate is None else convert_rate\n",
    "        sample_width = self.sample_width if convert_width is None else convert_width\n",
    "\n",
    "        # generate the WAV file contents\n",
    "        with io.BytesIO() as wav_file:\n",
    "            wav_writer = wave.open(wav_file, \"wb\")\n",
    "            try:  # note that we can't use context manager, since that was only added in Python 3.4\n",
    "                wav_writer.setframerate(sample_rate)\n",
    "                wav_writer.setsampwidth(sample_width)\n",
    "                wav_writer.setnchannels(1)\n",
    "                wav_writer.writeframes(raw_data)\n",
    "                wav_data = wav_file.getvalue()\n",
    "            finally:  # make sure resources are cleaned up\n",
    "                wav_writer.close()\n",
    "        return wav_data\n",
    "\n",
    "    def get_aiff_data(self, convert_rate=None, convert_width=None):\n",
    "        \"\"\"\n",
    "        Returns a byte string representing the contents of an AIFF-C file containing the audio represented by the ``AudioData`` instance.\n",
    "        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n",
    "        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n",
    "        Writing these bytes directly to a file results in a valid `AIFF-C file <https://en.wikipedia.org/wiki/Audio_Interchange_File_Format>`__.\n",
    "        \"\"\"\n",
    "        raw_data = self.get_raw_data(convert_rate, convert_width)\n",
    "        sample_rate = self.sample_rate if convert_rate is None else convert_rate\n",
    "        sample_width = self.sample_width if convert_width is None else convert_width\n",
    "\n",
    "        # the AIFF format is big-endian, so we need to covnert the little-endian raw data to big-endian\n",
    "        if hasattr(audioop, \"byteswap\"):  # ``audioop.byteswap`` was only added in Python 3.4\n",
    "            raw_data = audioop.byteswap(raw_data, sample_width)\n",
    "        else:  # manually reverse the bytes of each sample, which is slower but works well enough as a fallback\n",
    "            raw_data = raw_data[sample_width - 1::-1] + b\"\".join(raw_data[i + sample_width:i:-1] for i in range(sample_width - 1, len(raw_data), sample_width))\n",
    "\n",
    "        # generate the AIFF-C file contents\n",
    "        with io.BytesIO() as aiff_file:\n",
    "            aiff_writer = aifc.open(aiff_file, \"wb\")\n",
    "            try:  # note that we can't use context manager, since that was only added in Python 3.4\n",
    "                aiff_writer.setframerate(sample_rate)\n",
    "                aiff_writer.setsampwidth(sample_width)\n",
    "                aiff_writer.setnchannels(1)\n",
    "                aiff_writer.writeframes(raw_data)\n",
    "                aiff_data = aiff_file.getvalue()\n",
    "            finally:  # make sure resources are cleaned up\n",
    "                aiff_writer.close()\n",
    "        return aiff_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recogniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_threshold = 300\n",
    "dynamic_energy_treshold = True\n",
    "dynamic_energy_adjustment_damping = 0.15\n",
    "dynamic_energy_ratio = 1.5\n",
    "pause_threshold = 0.8  # seconds of non-speaking audio before a phrase is considered complete\n",
    "operation_timeout = None  # seconds after an internal operation (e.g., an API request) starts before it times out, or ``None`` for no timeout\n",
    "\n",
    "phrase_threshold = 1  # minimum seconds of speaking audio before we consider the speaking audio a phrase - values below this are ignored (for filtering out clicks and pops)\n",
    "non_speaking_duration = 0.5  # seconds of non-speaking audio to keep on both sides of the recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust ambient noise dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_ambient_noise(energy_threshold,duration=1):\n",
    "\n",
    "    seconds_per_buffer = (CHUNK + 0.0) / SAMPLE_RATE\n",
    "    elapsed_time = 0\n",
    "\n",
    "    # adjust energy threshold until a phrase starts\n",
    "    while True:\n",
    "        elapsed_time += seconds_per_buffer\n",
    "        if elapsed_time > duration: break\n",
    "        buffer = stream.read(CHUNK)\n",
    "        energy = audioop.rms(buffer, SAMPLE_WIDTH)  # energy of the audio signal\n",
    "\n",
    "        # dynamically adjust the energy threshold using asymmetric weighted average\n",
    "        damping = dynamic_energy_adjustment_damping ** seconds_per_buffer  # account for different chunk sizes and rates\n",
    "        target_energy = energy * dynamic_energy_ratio\n",
    "        energy_threshold = energy_threshold * damping + target_energy * (1 - damping)\n",
    "        return energy_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_threshold = adjust_for_ambient_noise(energy_threshold,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288.5583082391005"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowboy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snowboy/resources/models/snowboy.umdl'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"snowboy/resources/models/snowboy.umdl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file import *\n",
    "TOP_DIR = get_absolute_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_FILE = os.path.join(TOP_DIR, \"snowboy/resources/common.res\")\n",
    "model_str = \",\".join([\"snowboy/resources/models/computer.umdl\"])\n",
    "\n",
    "detector = SnowboyDetect(RESOURCE_FILE.encode(), model_str=model_str.encode())\n",
    "\n",
    "detector.SetAudioGain(1.0)\n",
    "detector.SetSensitivity(\",\".join([\"0.6\"]).encode())\n",
    "detector.ApplyFrontend(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowboy_hot_word(detector, CHUNK, SAMPLE_RATE,SAMPLE_WIDTH, stream):\n",
    "    snowboy_sample_rate = detector.SampleRate()\n",
    "    seconds_per_buffer = CHUNK/SAMPLE_RATE\n",
    "    resampling_state = None\n",
    "    \n",
    "    five_seconds_buffer_count = int(math.ceil(2/seconds_per_buffer))\n",
    "    half_second_buffer_count = int(math.ceil(0.5/seconds_per_buffer))\n",
    "    \n",
    "    frames = collections.deque(maxlen=five_seconds_buffer_count)\n",
    "    resampled_frames = collections.deque(maxlen=half_second_buffer_count)\n",
    "    \n",
    "    check_interval = 0.05\n",
    "    last_check = time.time()\n",
    "    while True:\n",
    "        #elapsed_time += seconds_per_buffer\n",
    "        \n",
    "        buffer = stream.read(CHUNK)\n",
    "        frames.append(buffer)\n",
    "        \n",
    "        resampled_buffer, resampling_state = audioop.ratecv(buffer, SAMPLE_WIDTH, 1, SAMPLE_RATE, snowboy_sample_rate, resampling_state)\n",
    "        resampled_frames.append(resampled_buffer)\n",
    "        \n",
    "        if time.time() - last_check > check_interval:\n",
    "            snowboy_result = detector.RunDetection(b\"\".join(resampled_frames))\n",
    "            #print(len(resampled_frames))\n",
    "            if snowboy_result == 0:\n",
    "                #print('kk')\n",
    "                print(len(resampled_frames))\n",
    "            if snowboy_result > 0:\n",
    "                print(snowboy_result)\n",
    "                break;\n",
    "            resampled_frames.clear()\n",
    "            last_check = time.time()\n",
    "            \n",
    "    return b\"\".join(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen(stream, CHUNK, SAMPLE_RATE, pause_threshold, phrase_threshold, non_speaking_duration,energy_threshold, detector=detector):\n",
    "    seconds_per_buffer = float(CHUNK)/SAMPLE_RATE\n",
    "    pause_buffer_count = int(math.ceil(pause_threshold / seconds_per_buffer))\n",
    "    phrase_buffer_count = int(math.ceil(phrase_threshold / seconds_per_buffer))\n",
    "    non_speaking_buffer_count = int(math.ceil(non_speaking_duration / seconds_per_buffer))\n",
    "    \n",
    "    elapsed_time = 0\n",
    "    buffer = b\"\"\n",
    "    while True:\n",
    "        frames = collections.deque()\n",
    "        \n",
    "        if detector is None:\n",
    "            while True:\n",
    "                buffer = stream.read(CHUNK)\n",
    "                frames.append(buffer)\n",
    "                if len(frames) > non_speaking_buffer_count:\n",
    "                    frames.popleft()\n",
    "                energy = audioop.rms(buffer, SAMPLE_WIDTH)\n",
    "                if energy > energy_threshold:\n",
    "                    print('hi')\n",
    "                    break;\n",
    "        else:\n",
    "            buffer = snowboy_hot_word(detector, CHUNK, SAMPLE_RATE,SAMPLE_WIDTH, stream)\n",
    "            frames.append(buffer)\n",
    "            \n",
    "        pause_count, phrase_count = 0,0\n",
    "        while True:\n",
    "            buffer = stream.read(CHUNK)\n",
    "            frames.append(buffer)\n",
    "            phrase_count += 1\n",
    "\n",
    "            energy = audioop.rms(buffer, SAMPLE_WIDTH)\n",
    "            if energy > energy_threshold:\n",
    "                print('hey')\n",
    "                pause_count = 0\n",
    "            else:\n",
    "                pause_count += 1\n",
    "\n",
    "            if pause_count > pause_buffer_count:\n",
    "                break;\n",
    "\n",
    "        phrase_count -= pause_count\n",
    "        if phrase_count >= phrase_buffer_count:\n",
    "            break;\n",
    "            \n",
    "    for i in range(pause_count - non_speaking_buffer_count):\n",
    "        frames.pop()\n",
    "        \n",
    "    frame_data = b\"\".join(frames)\n",
    "    \n",
    "    return(AudioData(frame_data, SAMPLE_RATE, SAMPLE_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n"
     ]
    }
   ],
   "source": [
    "a = listen(stream, CHUNK, SAMPLE_RATE, pause_threshold, phrase_threshold, non_speaking_duration,energy_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AudioData at 0x115f86eb8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = a.get_wav_data()\n",
    "with open('bla.wav', 'wb') as output:\n",
    "    output.write(wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lex chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('lex-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_name = 'computer'\n",
    "bot_alias = 'computer'\n",
    "user_id = '123456789'\n",
    "content_type = 'audio/l16; rate=16000; channels=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = a.get_raw_data(\n",
    "            convert_rate=16000, convert_width=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept = \"text/plain; charset=utf-8\"\n",
    "response = client.post_content(botName=bot_name, \n",
    "                               botAlias=bot_alias, \n",
    "                               userId=user_id, \n",
    "                               contentType=content_type, \n",
    "                               accept=accept, \n",
    "                               inputStream=raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '80917817-b676-4888-8e4c-551f0ae560ea',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'text/plain;charset=utf-8',\n",
       "   'date': 'Wed, 09 Oct 2019 16:54:37 GMT',\n",
       "   'x-amz-lex-dialog-state': 'Fulfilled',\n",
       "   'x-amz-lex-input-transcript': 'computer can you switch the lights on please',\n",
       "   'x-amz-lex-intent-name': 'lightsOn',\n",
       "   'x-amz-lex-message': 'I will turn the lights on',\n",
       "   'x-amz-lex-message-format': 'PlainText',\n",
       "   'x-amz-lex-slots': 'e30=',\n",
       "   'x-amzn-requestid': '80917817-b676-4888-8e4c-551f0ae560ea',\n",
       "   'content-length': '0',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0},\n",
       " 'contentType': 'text/plain;charset=utf-8',\n",
       " 'intentName': 'lightsOn',\n",
       " 'slots': {},\n",
       " 'message': 'I will turn the lights on',\n",
       " 'messageFormat': 'PlainText',\n",
       " 'dialogState': 'Fulfilled',\n",
       " 'inputTranscript': 'computer can you switch the lights on please',\n",
       " 'audioStream': <botocore.response.StreamingBody at 0x115fa31d0>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer can you switch the lights on please'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['inputTranscript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lightsOn'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['intentName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lights on\n"
     ]
    }
   ],
   "source": [
    "if response['intentName'] == 'lightsOn':\n",
    "    print('lights on')\n",
    "elif response['intentName'] == 'lightsOff':\n",
    "    print('lightsOff')\n",
    "else:\n",
    "    print('fuck off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightSwitch",
   "language": "python",
   "name": "lightswitch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
